{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XPHRDz6Q7rcs"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create a Doc object from the file owlcreek.txt\n"
      ],
      "metadata": {
        "id": "nwjZBUl9y7k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/owlcreek.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    doc = f.read()"
      ],
      "metadata": {
        "id": "zzyb7rfA8RNi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. How many tokens are contained in the file?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y52_OBALy-80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total tokens:\", len(doc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjvAIY8h8RAl",
        "outputId": "9301e42f-29e3-4775-ed4a-d459eb554142"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 21344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. How many sentences are contained in the file?"
      ],
      "metadata": {
        "id": "hXagGsLVzBRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(doc)\n",
        "for sent in doc.sents:\n",
        "  pass\n",
        "\n",
        "print(len(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k6-ejwc8QwC",
        "outputId": "a10d5f41-f470-48eb-c523-5645d646a3a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Print the second sentence in the document"
      ],
      "metadata": {
        "id": "PmsNzyGqzG9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s= list(doc.sents)[1]"
      ],
      "metadata": {
        "id": "TMDD9Qkn-y02"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "id": "DurKQiXxBhcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacdb149-4e78-466e-f08d-082cc013ae55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "The man's hands were behind\n",
              "his back, the wrists bound with a cord.  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. For each token in the sentence above, print its text, POS tag, dep tag and lemma."
      ],
      "metadata": {
        "id": "YhRiyV-rzOr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in s:\n",
        "  print(f\"{token.text:{15}} {token.pos_:{10}} {token.dep_:{12}} {token.lemma_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJZO0-5XvOxl",
        "outputId": "358e1115-35f9-42bf-83ea-cf552b7b98ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The             DET        det          the\n",
            "man             NOUN       poss         man\n",
            "'s              PART       case         's\n",
            "hands           NOUN       nsubj        hand\n",
            "were            AUX        ROOT         be\n",
            "behind          ADP        prep         behind\n",
            "\n",
            "               SPACE      dep          \n",
            "\n",
            "his             PRON       poss         his\n",
            "back            NOUN       pobj         back\n",
            ",               PUNCT      punct        ,\n",
            "the             DET        det          the\n",
            "wrists          NOUN       appos        wrist\n",
            "bound           VERB       acl          bind\n",
            "with            ADP        prep         with\n",
            "a               DET        det          a\n",
            "cord            NOUN       pobj         cord\n",
            ".               PUNCT      punct        .\n",
            "                SPACE      dep           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text.\n"
      ],
      "metadata": {
        "id": "hY8SYPnfzOnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "pattern = [\n",
        "    {\"LOWER\": \"swimming\"},\n",
        "    {\"LOWER\": \"vigorously\"}\n",
        "]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ],
      "metadata": {
        "id": "4r3a7gK6zqR2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " this code from my side to check the code is working or not  . In txt file there i cant found the \"Swimming\" word"
      ],
      "metadata": {
        "id": "aK5jna9iqcYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#matcher = Matcher(nlp.vocab)\n",
        "#\n",
        "#pattern = [\n",
        "#    {\"LOWER\": \"sergeant\"}\n",
        "#]\n",
        "#\n",
        "#matcher.add(\"sergeant\", [pattern])"
      ],
      "metadata": {
        "id": "oesJGQ7_p8Mb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches = matcher(doc)"
      ],
      "metadata": {
        "id": "SoP2Qn7Jmrn3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]\n",
        "    print(\"Matched phrase:\", span.text)"
      ],
      "metadata": {
        "id": "jxUG5G2jmoVU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Print the text surrounding each found match."
      ],
      "metadata": {
        "id": "rUZgzwQ3zOiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for match_id, start, end in matches:\n",
        "    span = doc[(start - 5):(end + 5)]\n",
        "    print(span , \"\\n\" , \"-\"*10)"
      ],
      "metadata": {
        "id": "fBvU0Kqrzqn0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JylFQ29npgsy"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}